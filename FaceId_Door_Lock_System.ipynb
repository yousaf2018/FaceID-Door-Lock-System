{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dried-syntax",
   "metadata": {},
   "source": [
    "## Dataset generation using opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "operational-genealogy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import keras\n",
    "import keras_metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "from random import shuffle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-phoenix",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_generation():\n",
    "    FaceClassifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    def face_detection(image):\n",
    "        gray_scale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        detected_face = FaceClassifier.detectMultiScale(gray_scale, 1.3, 5)\n",
    "        \n",
    "        if detected_face is ():\n",
    "            return None\n",
    "        for (x,y,w,h) in detected_face:\n",
    "            face = image[y:y+h,x:x+w]\n",
    "        return face\n",
    "    \n",
    "    videoCapture = cv2.VideoCapture(0)\n",
    "    image_id = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = videoCapture.read()\n",
    "        if face_detection(frame) is not None:\n",
    "            image_id+=1\n",
    "            face = cv2.resize(face_detection(frame), (250,250))\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "            #Saving images from web cam to local disk\n",
    "            file_name_path = \"Dataset/\"+\"Yousaf_\"+str(image_id)+'.jpg'\n",
    "            cv2.imwrite(file_name_path, face)\n",
    "            cv2.putText(face, str(image_id), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2 )\n",
    "            \n",
    "            cv2.imshow(\"Cropped_Face\", face)\n",
    "            if cv2.waitKey(1)==13 or int(image_id)==500:\n",
    "                break\n",
    "                \n",
    "    videoCapture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Data Collection is completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-forwarding",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faced-iraqi",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "existing-empire",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating labels for each person\n",
    "def label(image):\n",
    "    name = image.split(\"_\")[0]\n",
    "    #One hot encoding for four persons \n",
    "    if name == \"Yousaf\":\n",
    "        return 0\n",
    "    elif name == \"Qazi\":\n",
    "        return 1\n",
    "    elif name == \"Abdullah\":\n",
    "        return 2\n",
    "    elif name == \"Manzoor\":\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-branch",
   "metadata": {},
   "source": [
    "## Preparing dataset for deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-beginning",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tough-gathering",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    dataset = []\n",
    "    for image_name in tqdm(os.listdir(\"C:\\\\Users\\\\Marhaba\\\\Desktop\\\\Computer Vision\\\\FaceId_Door_Lock_System\\\\Dataset\")):\n",
    "        image_path = os.path.join(\"C:\\\\Users\\\\Marhaba\\\\Desktop\\\\Computer Vision\\\\FaceId_Door_Lock_System\\\\Dataset\",image_name)\n",
    "        image = cv2.imread(image_path,cv2.IMREAD_GRAYSCALE)\n",
    "        dataset.append([image,label(image_name)])\n",
    "    shuffle(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "generous-princeton",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:02<00:00, 882.60it/s] \n"
     ]
    }
   ],
   "source": [
    "dataset = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "naval-crash",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 63,  62,  62, ..., 128, 128, 128],\n",
       "        [ 63,  62,  61, ..., 128, 129, 129],\n",
       "        [ 62,  62,  61, ..., 128, 128, 128],\n",
       "        ...,\n",
       "        [106, 106, 105, ..., 144, 144, 143],\n",
       "        [106, 105, 105, ..., 151, 149, 148],\n",
       "        [106, 105, 105, ..., 152, 151, 150]], dtype=uint8),\n",
       " 2]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "optional-weekly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 250, 250, 1)\n",
      "(1600, 4)\n",
      "(400, 250, 250, 1)\n",
      "(400, 4)\n"
     ]
    }
   ],
   "source": [
    "#Splitting dataset into training and testing \n",
    "train_dataset = dataset[:1600]\n",
    "test_dataset = dataset[1600::]\n",
    "X = np.array([k[0] for k in train_dataset]).reshape(-1,250,250,1)\n",
    "print(X.shape)\n",
    "Y = [j[1] for j in train_dataset]\n",
    "Y = to_categorical(Y)\n",
    "print(Y.shape)\n",
    "X_test = np.array([k[0] for k in test_dataset]).reshape(-1,250,250,1)\n",
    "print(X_test.shape)\n",
    "Y_test = [j[1] for j in test_dataset]\n",
    "Y_test = to_categorical(Y_test)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-humanitarian",
   "metadata": {},
   "source": [
    "## CNN architecture for face recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "black-royalty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "smart-shakespeare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Marhaba\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 60, 60, 32)        3904      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 60, 60, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 29, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 29, 29, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              51384320  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 16388     \n",
      "=================================================================\n",
      "Total params: 68,385,988\n",
      "Trainable params: 68,385,412\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#CNN Architecture for face recognition\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(250,250,1)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "flexible-fleece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'Variable:0' shape=() dtype=int32> tp\n",
      "tracking <tf.Variable 'Variable_1:0' shape=() dtype=int32> fp\n",
      "tracking <tf.Variable 'Variable_2:0' shape=() dtype=int32> tp\n",
      "tracking <tf.Variable 'Variable_3:0' shape=() dtype=int32> fn\n",
      "tracking <tf.Variable 'Variable_4:0' shape=() dtype=int32> tp\n",
      "tracking <tf.Variable 'Variable_5:0' shape=() dtype=int32> fp\n",
      "tracking <tf.Variable 'Variable_6:0' shape=() dtype=int32> tp\n",
      "tracking <tf.Variable 'Variable_7:0' shape=() dtype=int32> fn\n",
      "WARNING:tensorflow:From C:\\Users\\Marhaba\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1120 samples, validate on 480 samples\n",
      "Epoch 1/10\n",
      "1120/1120 [==============================] - 92s 82ms/step - loss: 3.4897 - accuracy: 0.8696 - precision: 0.7406 - recall: 0.7396 - f1_score: 0.7393 - val_loss: 1279.9519 - val_accuracy: 0.2521 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1120/1120 [==============================] - 86s 76ms/step - loss: 2.4339 - accuracy: 0.9661 - precision: 0.9734 - recall: 0.9737 - f1_score: 0.9734 - val_loss: 524.1981 - val_accuracy: 0.4583 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1120/1120 [==============================] - 83s 74ms/step - loss: 3.8363 - accuracy: 0.9598 - precision: 0.9729 - recall: 0.9581 - f1_score: 0.9653 - val_loss: 10157.9058 - val_accuracy: 0.2521 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1120/1120 [==============================] - 84s 75ms/step - loss: 0.8698 - accuracy: 0.9875 - precision: 0.9947 - recall: 0.9646 - f1_score: 0.9789 - val_loss: 411.3887 - val_accuracy: 0.2937 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1120/1120 [==============================] - 82s 73ms/step - loss: 0.2097 - accuracy: 0.9964 - precision: 1.0000 - recall: 0.9980 - f1_score: 0.9990 - val_loss: 11.5291 - val_accuracy: 0.9125 - val_precision: 1.0000 - val_recall: 0.7828 - val_f1_score: 0.8769\n",
      "Epoch 6/10\n",
      "1120/1120 [==============================] - 94s 84ms/step - loss: 0.1513 - accuracy: 0.9964 - precision: 0.9994 - recall: 1.0000 - f1_score: 0.9997 - val_loss: 4.3268 - val_accuracy: 0.9583 - val_precision: 1.0000 - val_recall: 0.9218 - val_f1_score: 0.9587\n",
      "Epoch 7/10\n",
      "1120/1120 [==============================] - 93s 83ms/step - loss: 0.4736 - accuracy: 0.9920 - precision: 1.0000 - recall: 0.9993 - f1_score: 0.9996 - val_loss: 0.0316 - val_accuracy: 0.9979 - val_precision: 1.0000 - val_recall: 0.9917 - val_f1_score: 0.9958\n",
      "Epoch 8/10\n",
      "1120/1120 [==============================] - 98s 88ms/step - loss: 0.8503 - accuracy: 0.9929 - precision: 0.9940 - recall: 0.9916 - f1_score: 0.9928 - val_loss: 11.3755 - val_accuracy: 0.9229 - val_precision: 1.0000 - val_recall: 0.8577 - val_f1_score: 0.9230\n",
      "Epoch 9/10\n",
      "1120/1120 [==============================] - 90s 80ms/step - loss: 1.3248 - accuracy: 0.9902 - precision: 0.9986 - recall: 0.9838 - f1_score: 0.9910 - val_loss: 2.1162 - val_accuracy: 0.9875 - val_precision: 1.0000 - val_recall: 0.9797 - val_f1_score: 0.9897\n",
      "Epoch 10/10\n",
      "1120/1120 [==============================] - 86s 77ms/step - loss: 0.4617 - accuracy: 0.9973 - precision: 0.9993 - recall: 1.0000 - f1_score: 0.9997 - val_loss: 17.9571 - val_accuracy: 0.8750 - val_precision: 1.0000 - val_recall: 0.9451 - val_f1_score: 0.9717\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy',keras_metrics.precision(),keras_metrics.recall(),keras_metrics.f1_score()])\n",
    "history=model.fit(X, Y, epochs=10, batch_size=32, verbose=1, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "innocent-maine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 5s 12ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[14.30105297088623,\n",
       " 0.9075000286102295,\n",
       " 1.0,\n",
       " 0.9506106972694397,\n",
       " 0.9744839072227478]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,Y_test,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "scientific-pledge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_f1_score', 'loss', 'accuracy', 'precision', 'recall', 'f1_score'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "wrong-denial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_f1_score', 'loss', 'accuracy', 'precision', 'recall', 'f1_score'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "plt.plot(history.history['precision'])\n",
    "plt.plot(history.history['recall'])\n",
    "plt.plot(history.history['f1_score'])\n",
    "plt.title('Precision Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Number of epocs')\n",
    "plt.legend(['Precision', 'Recall','F1 Score'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "signal-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Saved_Model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "veterinary-november",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved!\n",
      "Model Loaded!\n"
     ]
    }
   ],
   "source": [
    "# saving and loading the model weights\n",
    " \n",
    "# save model\n",
    "model.save_weights('gfgModelWeights')\n",
    "print('Model Saved!')\n",
    " \n",
    "# load model\n",
    "savedModel = model.load_weights('gfgModelWeights')\n",
    "print('Model Loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "moral-forward",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 60, 60, 32)        3904      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 60, 60, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 29, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 29, 29, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 29, 29, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4096)              51384320  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 16388     \n",
      "=================================================================\n",
      "Total params: 68,385,988\n",
      "Trainable params: 68,385,412\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#CNN Architecture for face recognition\n",
    "model2 = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(250,250,1)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "lyric-subdivision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'Variable_8:0' shape=() dtype=int32> tp\n",
      "tracking <tf.Variable 'Variable_9:0' shape=() dtype=int32> fp\n",
      "tracking <tf.Variable 'Variable_10:0' shape=() dtype=int32> tp\n",
      "tracking <tf.Variable 'Variable_11:0' shape=() dtype=int32> fn\n",
      "tracking <tf.Variable 'Variable_12:0' shape=() dtype=int32> tp\n",
      "tracking <tf.Variable 'Variable_13:0' shape=() dtype=int32> fp\n",
      "tracking <tf.Variable 'Variable_14:0' shape=() dtype=int32> tp\n",
      "tracking <tf.Variable 'Variable_15:0' shape=() dtype=int32> fn\n",
      "Model Loaded!\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy',keras_metrics.precision(),keras_metrics.recall(),keras_metrics.f1_score()])\n",
    "# load model\n",
    "savedModel = model2.load_weights('gfgModelWeights')\n",
    "print('Model Loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "liked-nothing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 3s 8ms/sample - loss: 14.3011 - acc: 0.9075 - precision: 1.0000 - recall: 0.9757 - f1_score: 0.9872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[14.30105297088623, 0.9075, 1.0, 0.9756993, 0.98716015]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_test,Y_test,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-charles",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
