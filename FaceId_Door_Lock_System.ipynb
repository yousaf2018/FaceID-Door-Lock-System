{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dried-syntax",
   "metadata": {},
   "source": [
    "## Dataset generation using opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "operational-genealogy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marhaba\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Marhaba\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Marhaba\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Marhaba\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Marhaba\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Marhaba\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Marhaba\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Marhaba\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Marhaba\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Marhaba\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Marhaba\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Marhaba\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import keras\n",
    "import keras_metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "from random import shuffle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-phoenix",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_generation():\n",
    "    FaceClassifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    def face_detection(image):\n",
    "        gray_scale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        detected_face = FaceClassifier.detectMultiScale(gray_scale, 1.3, 5)\n",
    "        \n",
    "        if detected_face is ():\n",
    "            return None\n",
    "        for (x,y,w,h) in detected_face:\n",
    "            face = image[y:y+h,x:x+w]\n",
    "        return face\n",
    "    \n",
    "    videoCapture = cv2.VideoCapture(0)\n",
    "    image_id = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = videoCapture.read()\n",
    "        if face_detection(frame) is not None:\n",
    "            image_id+=1\n",
    "            face = cv2.resize(face_detection(frame), (250,250))\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "            #Saving images from web cam to local disk\n",
    "            file_name_path = \"Dataset/\"+\"Yousaf_\"+str(image_id)+'.jpg'\n",
    "            cv2.imwrite(file_name_path, face)\n",
    "            cv2.putText(face, str(image_id), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2 )\n",
    "            \n",
    "            cv2.imshow(\"Cropped_Face\", face)\n",
    "            if cv2.waitKey(1)==13 or int(image_id)==500:\n",
    "                break\n",
    "                \n",
    "    videoCapture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Data Collection is completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-forwarding",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faced-iraqi",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "existing-empire",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating labels for each person\n",
    "def label(image):\n",
    "    name = image.split(\"_\")[0]\n",
    "    #One hot encoding for four persons \n",
    "    if name == \"Yousaf\":\n",
    "        return 0\n",
    "    elif name == \"Qazi\":\n",
    "        return 1\n",
    "    elif name == \"Abdullah\":\n",
    "        return 2\n",
    "    elif name == \"Manzoor\":\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-branch",
   "metadata": {},
   "source": [
    "## Preparing dataset for deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-beginning",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "tough-gathering",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    dataset = []\n",
    "    for image_name in tqdm(os.listdir(\"C:\\\\Users\\\\Marhaba\\\\Desktop\\\\Computer Vision\\\\FaceId_Door_Lock_System\\\\Dataset\")):\n",
    "        image_path = os.path.join(\"C:\\\\Users\\\\Marhaba\\\\Desktop\\\\Computer Vision\\\\FaceId_Door_Lock_System\\\\Dataset\",image_name)\n",
    "        image = cv2.imread(image_path,cv2.IMREAD_GRAYSCALE)\n",
    "        dataset.append([image,label(image_name)])\n",
    "    shuffle(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "generous-princeton",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:01<00:00, 1222.39it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "naval-crash",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[130, 130, 130, ...,  47,  48,  48],\n",
       "        [131, 131, 130, ...,  48,  48,  49],\n",
       "        [132, 132, 131, ...,  48,  48,  48],\n",
       "        ...,\n",
       "        [ 59,  58,  57, ...,  24,  23,  23],\n",
       "        [ 59,  58,  57, ...,  24,  23,  23],\n",
       "        [ 59,  58,  57, ...,  23,  23,  23]], dtype=uint8),\n",
       " 3]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "optional-weekly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 250, 250, 1)\n",
      "(400, 250, 250, 1)\n"
     ]
    }
   ],
   "source": [
    "#Splitting dataset into training and testing \n",
    "train_dataset = dataset[:1600]\n",
    "test_dataset = dataset[1600::]\n",
    "X = np.array([k[0] for k in train_dataset]).reshape(-1,250,250,1)\n",
    "print(X.shape)\n",
    "Y = [j[1] for j in train_dataset]\n",
    "Y = to_categorical(Y)\n",
    "X_test = np.array([k[0] for k in test_dataset]).reshape(-1,250,250,1)\n",
    "print(X_test.shape)\n",
    "Y_test = [j[1] for j in test_dataset]\n",
    "Y_test = to_categorical(Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-humanitarian",
   "metadata": {},
   "source": [
    "## CNN architecture for face recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-royalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "smart-shakespeare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 250, 250, 64)      1664      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 250, 250, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 124, 124, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 124, 124, 128)     73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 124, 124, 128)     512       \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 124, 124, 64)      73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 124, 124, 64)      256       \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 984064)            0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1048)              1031300120\n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1048)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 4)                 4196      \n",
      "=================================================================\n",
      "Total params: 1,031,454,652\n",
      "Trainable params: 1,031,454,140\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#CNN Architecture for face recognition\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\", input_shape=(250,250,1)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1048, activation='relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-fleece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'Variable:0' shape=() dtype=int32> tp\n",
      "tracking <tf.Variable 'Variable_1:0' shape=() dtype=int32> fp\n",
      "tracking <tf.Variable 'Variable_2:0' shape=() dtype=int32> tp\n",
      "tracking <tf.Variable 'Variable_3:0' shape=() dtype=int32> fn\n",
      "tracking <tf.Variable 'Variable_4:0' shape=() dtype=int32> tp\n",
      "tracking <tf.Variable 'Variable_5:0' shape=() dtype=int32> fp\n",
      "tracking <tf.Variable 'Variable_6:0' shape=() dtype=int32> tp\n",
      "tracking <tf.Variable 'Variable_7:0' shape=() dtype=int32> fn\n",
      "WARNING:tensorflow:From C:\\Users\\Marhaba\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1120 samples, validate on 480 samples\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy',keras_metrics.precision(),keras_metrics.recall(),keras_metrics.f1_score()])\n",
    "history=model.fit(X, Y, epochs=10, batch_size=32, verbose=1, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-maine",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,Y_test,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-pledge",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-denial",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "plt.plot(history.history['precision'])\n",
    "plt.plot(history.history['recall'])\n",
    "plt.plot(history.history['f1_score'])\n",
    "plt.title('Precision Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Number of epocs')\n",
    "plt.legend(['Precision', 'Recall','F1 Score'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Saved_Model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-november",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving and loading the model weights\n",
    " \n",
    "# save model\n",
    "model.save_weights('gfgModelWeights')\n",
    "print('Model Saved!')\n",
    " \n",
    "# load model\n",
    "savedModel = model.load_weights('gfgModelWeights')\n",
    "print('Model Loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "moral-forward",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Marhaba\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 60, 60, 32)        3904      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 60, 60, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 29, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 29, 29, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 29, 29, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4096)              51384320  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 16388     \n",
      "=================================================================\n",
      "Total params: 68,385,988\n",
      "Trainable params: 68,385,412\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#CNN Architecture for face recognition\n",
    "model2 = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\", input_shape=(250,250,1)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1048, activation='relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy',keras_metrics.precision(),keras_metrics.recall(),keras_metrics.f1_score()])\n",
    "# load model\n",
    "savedModel = model2.load_weights('gfgModelWeights')\n",
    "print('Model Loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.evaluate(X_test,Y_test,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-charles",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_model():\n",
    "    FaceClassifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    def face_detection(image):\n",
    "        gray_scale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        detected_face = FaceClassifier.detectMultiScale(gray_scale, 1.3, 5)\n",
    "        \n",
    "        if detected_face is ():\n",
    "            return None\n",
    "        for (x,y,w,h) in detected_face:\n",
    "            face = image[y:y+h,x:x+w]\n",
    "        return face\n",
    "    \n",
    "    videoCapture = cv2.VideoCapture(0)    \n",
    "    while True:\n",
    "        ret, frame = videoCapture.read()\n",
    "        if face_detection(frame) is not None:\n",
    "            face = cv2.resize(face_detection(frame), (250,250))\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "            cv2.putText(face, str(\"User\"), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2 )\n",
    "            cv2.imshow(\"Cropped_Face\", face)\n",
    "            prediction = model2.predict_classes(face.reshape(-1, 250, 250, 1))\n",
    "            print(prediction)\n",
    "            if cv2.waitKey(1)==13:\n",
    "                break\n",
    "                \n",
    "    videoCapture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Data Collection is completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-joint",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model2.predict_pr(X[19].reshape(-1, 250, 250, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-specification",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-reproduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-occasions",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
