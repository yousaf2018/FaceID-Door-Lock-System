{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dried-syntax",
   "metadata": {},
   "source": [
    "## Dataset generation using opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "operational-genealogy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marhaba\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Marhaba\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Marhaba\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Marhaba\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Marhaba\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Marhaba\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Marhaba\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Marhaba\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Marhaba\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Marhaba\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Marhaba\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Marhaba\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import keras\n",
    "import keras_metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "from random import shuffle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa0e28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "print(device)\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9d316ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Marhaba\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 60, 60, 32)        3904      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 60, 60, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 29, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 29, 29, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 29, 29, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1048)              13147160  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 4196      \n",
      "=================================================================\n",
      "Total params: 13,206,908\n",
      "Trainable params: 13,206,716\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#AlexNet Architecture for EC estimation\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(250,250,1)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1048, activation='relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "electrical-phoenix",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_generation():\n",
    "    FaceClassifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    def face_detection(image):\n",
    "        gray_scale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        detected_face = FaceClassifier.detectMultiScale(gray_scale, 1.3, 5)\n",
    "        \n",
    "        if detected_face is ():\n",
    "            return None\n",
    "        for (x,y,w,h) in detected_face:\n",
    "            face = image[y:y+h,x:x+w]\n",
    "        return face\n",
    "    \n",
    "    videoCapture = cv2.VideoCapture(0)\n",
    "    image_id = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = videoCapture.read()\n",
    "        if face_detection(frame) is not None:\n",
    "            image_id+=1\n",
    "            face = cv2.resize(face_detection(frame), (250,250))\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "            #Saving images from web cam to local disk\n",
    "            file_name_path = \"Dataset/\"+\"Yousaf_\"+str(image_id)+'.jpg'\n",
    "            cv2.imwrite(file_name_path, face)\n",
    "            cv2.putText(face, str(image_id), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2 )\n",
    "            \n",
    "            cv2.imshow(\"Cropped_Face\", face)\n",
    "            if cv2.waitKey(1)==13 or int(image_id)==500:\n",
    "                break\n",
    "                \n",
    "    videoCapture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Data Collection is completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adjacent-forwarding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Collection is completed\n"
     ]
    }
   ],
   "source": [
    "dataset_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faced-iraqi",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "existing-empire",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating labels for each person\n",
    "def label(image):\n",
    "    name = image.split(\"_\")[0]\n",
    "    #One hot encoding for four persons \n",
    "    if name == \"Yousaf\":\n",
    "        return 0\n",
    "    elif name == \"Qazi\":\n",
    "        return 1\n",
    "    elif name == \"Abdullah\":\n",
    "        return 2\n",
    "    elif name == \"Manzoor\":\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-branch",
   "metadata": {},
   "source": [
    "## Preparing dataset for deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-beginning",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "tough-gathering",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    dataset = []\n",
    "    for image_name in tqdm(os.listdir(\"C:\\\\Users\\Mahmood Yousaf\\\\Desktop\\\\FaceID-Door-Lock-System\\\\Dataset\")):\n",
    "        image_path = os.path.join(\"C:\\\\Users\\Mahmood Yousaf\\\\Desktop\\\\FaceID-Door-Lock-System\\\\Dataset\",image_name)\n",
    "        image = cv2.imread(image_path,cv2.IMREAD_GRAYSCALE)\n",
    "        dataset.append([image,label(image_name)])\n",
    "    shuffle(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "generous-princeton",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\Mahmood Yousaf\\\\Desktop\\\\FaceID-Door-Lock-System\\\\Dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-12b5b58cf1bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-d33e26f79dfd>\u001b[0m in \u001b[0;36mload_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mimage_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:\\\\Users\\Mahmood Yousaf\\\\Desktop\\\\FaceID-Door-Lock-System\\\\Dataset\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mimage_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:\\\\Users\\Mahmood Yousaf\\\\Desktop\\\\FaceID-Door-Lock-System\\\\Dataset\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\Mahmood Yousaf\\\\Desktop\\\\FaceID-Door-Lock-System\\\\Dataset'"
     ]
    }
   ],
   "source": [
    "dataset = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "naval-crash",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 86,  78,  68, ..., 118, 118, 118],\n",
       "        [ 80,  73,  64, ..., 117, 118, 118],\n",
       "        [ 73,  68,  60, ..., 117, 118, 118],\n",
       "        ...,\n",
       "        [ 84,  83,  82, ...,  58,  52,  50],\n",
       "        [ 83,  82,  81, ...,  64,  58,  54],\n",
       "        [ 83,  82,  81, ...,  67,  59,  56]], dtype=uint8),\n",
       " 1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "optional-weekly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 250, 250, 1)\n",
      "(400, 250, 250, 1)\n"
     ]
    }
   ],
   "source": [
    "#Splitting dataset into training and testing \n",
    "train_dataset = dataset[:1600]\n",
    "test_dataset = dataset[1600::]\n",
    "X = np.array([k[0] for k in train_dataset]).reshape(-1,250,250,1)\n",
    "print(X.shape)\n",
    "Y = [j[1] for j in train_dataset]\n",
    "Y = to_categorical(Y)\n",
    "X_test = np.array([k[0] for k in test_dataset]).reshape(-1,250,250,1)\n",
    "print(X_test.shape)\n",
    "Y_test = [j[1] for j in test_dataset]\n",
    "Y_test = to_categorical(Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-humanitarian",
   "metadata": {},
   "source": [
    "## CNN architecture for face recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "black-royalty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "flexible-fleece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mahmood Yousaf\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\base_layer.py:1348: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`layer.updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "35/35 [==============================] - ETA: 0s - loss: 4.3329 - accuracy: 0.8661 - precision: 0.8746 - recall: 0.8045 - f1_score: 0.8371WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "35/35 [==============================] - 17s 41ms/step - loss: 4.3329 - accuracy: 0.8661 - precision: 0.8746 - recall: 0.8045 - f1_score: 0.8371 - val_loss: 116.4564 - val_accuracy: 0.6292 - val_precision: 0.9442 - val_recall: 0.7587 - val_f1_score: 0.8388\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.0522 - accuracy: 0.9946 - precision: 0.9613 - recall: 0.7260 - f1_score: 0.8267 - val_loss: 77.0406 - val_accuracy: 0.5083 - val_precision: 0.9725 - val_recall: 0.7231 - val_f1_score: 0.8289\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.0771 - accuracy: 0.9920 - precision: 0.9778 - recall: 0.7161 - f1_score: 0.8265 - val_loss: 26.1611 - val_accuracy: 0.5104 - val_precision: 0.9805 - val_recall: 0.7128 - val_f1_score: 0.8253\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.0765 - accuracy: 0.9920 - precision: 0.9830 - recall: 0.7106 - f1_score: 0.8248 - val_loss: 6.8043 - val_accuracy: 0.8542 - val_precision: 0.9850 - val_recall: 0.7301 - val_f1_score: 0.8386\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.0025 - accuracy: 0.9991 - precision: 0.9869 - recall: 0.7453 - f1_score: 0.8492 - val_loss: 0.4754 - val_accuracy: 0.9812 - val_precision: 0.9877 - val_recall: 0.7718 - val_f1_score: 0.8665\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.0302 - accuracy: 0.9982 - precision: 0.9882 - recall: 0.7930 - f1_score: 0.8799 - val_loss: 1.4520 - val_accuracy: 0.9312 - val_precision: 0.9895 - val_recall: 0.8101 - val_f1_score: 0.8908\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.0291 - accuracy: 0.9982 - precision: 0.9904 - recall: 0.8241 - f1_score: 0.8996 - val_loss: 0.1135 - val_accuracy: 0.9937 - val_precision: 0.9913 - val_recall: 0.8369 - val_f1_score: 0.9076\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.0728 - accuracy: 0.9937 - precision: 0.9920 - recall: 0.8478 - f1_score: 0.9142 - val_loss: 5.2386e-05 - val_accuracy: 1.0000 - val_precision: 0.9926 - val_recall: 0.8573 - val_f1_score: 0.9200\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.2331 - accuracy: 0.9902 - precision: 0.9924 - recall: 0.8660 - f1_score: 0.9249 - val_loss: 0.9256 - val_accuracy: 0.8854 - val_precision: 0.9925 - val_recall: 0.8660 - val_f1_score: 0.9249\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.0208 - accuracy: 0.9982 - precision: 0.9929 - recall: 0.8667 - f1_score: 0.9255 - val_loss: 0.3288 - val_accuracy: 0.9875 - val_precision: 0.9933 - val_recall: 0.8735 - val_f1_score: 0.9295\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.0212 - accuracy: 0.9982 - precision: 0.9937 - recall: 0.8795 - f1_score: 0.9331 - val_loss: 0.0163 - val_accuracy: 0.9937 - val_precision: 0.9940 - val_recall: 0.8851 - val_f1_score: 0.9364\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 7.3826e-07 - accuracy: 1.0000 - precision: 0.9943 - recall: 0.8901 - f1_score: 0.9393 - val_loss: 2.0916e-05 - val_accuracy: 1.0000 - val_precision: 0.9946 - val_recall: 0.8948 - val_f1_score: 0.9420\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.0293 - accuracy: 0.9982 - precision: 0.9948 - recall: 0.8988 - f1_score: 0.9444 - val_loss: 4.9670e-09 - val_accuracy: 1.0000 - val_precision: 0.9950 - val_recall: 0.9028 - val_f1_score: 0.9466\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.0047 - accuracy: 0.9991 - precision: 0.9951 - recall: 0.9064 - f1_score: 0.9487 - val_loss: 0.2012 - val_accuracy: 0.9875 - val_precision: 0.9952 - val_recall: 0.9094 - val_f1_score: 0.9504\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.0567 - accuracy: 0.9946 - precision: 0.9954 - recall: 0.9123 - f1_score: 0.9520 - val_loss: 0.2308 - val_accuracy: 0.9771 - val_precision: 0.9956 - val_recall: 0.9141 - val_f1_score: 0.9531\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.1004 - accuracy: 0.9946 - precision: 0.9957 - recall: 0.9163 - f1_score: 0.9544 - val_loss: 2.1471 - val_accuracy: 0.8854 - val_precision: 0.9958 - val_recall: 0.9144 - val_f1_score: 0.9534\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4615 - accuracy: 0.9875 - precision: 0.9958 - recall: 0.9127 - f1_score: 0.9525 - val_loss: 38.0118 - val_accuracy: 0.5354 - val_precision: 0.9883 - val_recall: 0.9149 - val_f1_score: 0.9502\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.0775 - accuracy: 0.9964 - precision: 0.9835 - recall: 0.9172 - f1_score: 0.9492 - val_loss: 4.2440e-07 - val_accuracy: 1.0000 - val_precision: 0.9840 - val_recall: 0.9194 - val_f1_score: 0.9506\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.1357 - accuracy: 0.9911 - precision: 0.9843 - recall: 0.9216 - f1_score: 0.9519 - val_loss: 0.0053 - val_accuracy: 0.9979 - val_precision: 0.9847 - val_recall: 0.9235 - val_f1_score: 0.9531\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.0564 - accuracy: 0.9973 - precision: 0.9850 - recall: 0.9255 - f1_score: 0.9543 - val_loss: 1.2352 - val_accuracy: 0.9667 - val_precision: 0.9854 - val_recall: 0.9267 - val_f1_score: 0.9552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.0947 - accuracy: 0.9955 - precision: 0.9858 - recall: 0.9278 - f1_score: 0.9559 - val_loss: 0.0513 - val_accuracy: 0.9937 - val_precision: 0.9861 - val_recall: 0.9294 - val_f1_score: 0.9569\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.1093 - accuracy: 0.9937 - precision: 0.9865 - recall: 0.9309 - f1_score: 0.9579 - val_loss: 1.3182 - val_accuracy: 0.9812 - val_precision: 0.9866 - val_recall: 0.9324 - val_f1_score: 0.9587\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.1718 - accuracy: 0.9973 - precision: 0.9867 - recall: 0.9340 - f1_score: 0.9596 - val_loss: 0.0295 - val_accuracy: 0.9979 - val_precision: 0.9869 - val_recall: 0.9353 - val_f1_score: 0.9604\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.0194 - accuracy: 0.9973 - precision: 0.9872 - recall: 0.9366 - f1_score: 0.9613 - val_loss: 1.2418e-09 - val_accuracy: 1.0000 - val_precision: 0.9875 - val_recall: 0.9380 - val_f1_score: 0.9621\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.0067 - accuracy: 0.9991 - precision: 0.9878 - recall: 0.9393 - f1_score: 0.9629 - val_loss: 0.1274 - val_accuracy: 0.9958 - val_precision: 0.9880 - val_recall: 0.9403 - val_f1_score: 0.9636\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.0102 - accuracy: 0.9982 - precision: 0.9882 - recall: 0.9414 - f1_score: 0.9643 - val_loss: 1.4901e-09 - val_accuracy: 1.0000 - val_precision: 0.9884 - val_recall: 0.9426 - val_f1_score: 0.9650\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.0251 - accuracy: 0.9991 - precision: 0.9887 - recall: 0.9436 - f1_score: 0.9656 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.9889 - val_recall: 0.9447 - val_f1_score: 0.9663\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.0686 - accuracy: 0.9973 - precision: 0.9891 - recall: 0.9457 - f1_score: 0.9669 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.9893 - val_recall: 0.9466 - val_f1_score: 0.9675\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.0785 - accuracy: 0.9964 - precision: 0.9893 - recall: 0.9476 - f1_score: 0.9680 - val_loss: 0.0863 - val_accuracy: 0.9958 - val_precision: 0.9895 - val_recall: 0.9483 - val_f1_score: 0.9685\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.1762 - accuracy: 0.9946 - precision: 0.9896 - recall: 0.9490 - f1_score: 0.9689 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.9897 - val_recall: 0.9498 - val_f1_score: 0.9693\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.0290 - accuracy: 0.9991 - precision: 0.9898 - recall: 0.9506 - f1_score: 0.9698 - val_loss: 0.0281 - val_accuracy: 0.9979 - val_precision: 0.9899 - val_recall: 0.9514 - val_f1_score: 0.9703\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision: 0.9900 - recall: 0.9522 - f1_score: 0.9707 - val_loss: 0.0219 - val_accuracy: 0.9979 - val_precision: 0.9901 - val_recall: 0.9529 - val_f1_score: 0.9712\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.0345 - accuracy: 0.9982 - precision: 0.9903 - recall: 0.9536 - f1_score: 0.9716 - val_loss: 0.2108 - val_accuracy: 0.9937 - val_precision: 0.9903 - val_recall: 0.9543 - val_f1_score: 0.9720\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.0927 - accuracy: 0.9964 - precision: 0.9903 - recall: 0.9550 - f1_score: 0.9723 - val_loss: 25.7707 - val_accuracy: 0.8333 - val_precision: 0.9904 - val_recall: 0.9548 - val_f1_score: 0.9723\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.0477 - accuracy: 0.9955 - precision: 0.9905 - recall: 0.9548 - f1_score: 0.9723 - val_loss: 3.3662 - val_accuracy: 0.9604 - val_precision: 0.9907 - val_recall: 0.9551 - val_f1_score: 0.9726\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.2564 - accuracy: 0.9946 - precision: 0.9908 - recall: 0.9553 - f1_score: 0.9727 - val_loss: 9.9341e-10 - val_accuracy: 1.0000 - val_precision: 0.9909 - val_recall: 0.9559 - val_f1_score: 0.9731\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 2.7667e-04 - accuracy: 1.0000 - precision: 0.9911 - recall: 0.9565 - f1_score: 0.9735 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.9912 - val_recall: 0.9571 - val_f1_score: 0.9739\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision: 0.9913 - recall: 0.9577 - f1_score: 0.9742 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.9914 - val_recall: 0.9582 - val_f1_score: 0.9746\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision: 0.9916 - recall: 0.9588 - f1_score: 0.9749 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.9917 - val_recall: 0.9593 - val_f1_score: 0.9752\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision: 0.9918 - recall: 0.9598 - f1_score: 0.9755 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.9919 - val_recall: 0.9603 - val_f1_score: 0.9759\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy',keras_metrics.precision(),keras_metrics.recall(),keras_metrics.f1_score()])\n",
    "history=model.fit(X, Y, epochs=40, batch_size=32, verbose=1, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "innocent-maine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "13/13 [==============================] - 1s 24ms/step - loss: 0.0443 - accuracy: 0.9975 - precision: 0.9919 - recall: 0.9606 - f1_score: 0.9760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.044279154390096664,\n",
       " 0.9975000023841858,\n",
       " 0.9919463396072388,\n",
       " 0.9606257081031799,\n",
       " 0.9760348200798035]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,Y_test,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "scientific-pledge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'f1_score', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_f1_score'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "wrong-denial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'f1_score', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_f1_score'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "plt.plot(history.history['precision'])\n",
    "plt.plot(history.history['recall'])\n",
    "plt.plot(history.history['f1_score'])\n",
    "plt.title('Precision Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Number of epocs')\n",
    "plt.legend(['Precision', 'Recall','F1 Score'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "400e0fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved!\n",
      "Model Loaded!\n"
     ]
    }
   ],
   "source": [
    "# saving and loading the model weights\n",
    " \n",
    "# save model\n",
    "model.save_weights('faceRecognitionModel')\n",
    "print('Model Saved!')\n",
    " \n",
    "# load model\n",
    "savedModel = model.load_weights('faceRecognitionModel')\n",
    "print('Model Loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65840ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "signal-diploma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Marhaba\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 60, 60, 32)        3904      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 60, 60, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 29, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 29, 29, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1048)              13147160  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 4196      \n",
      "=================================================================\n",
      "Total params: 13,206,908\n",
      "Trainable params: 13,206,716\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "tracking <tf.Variable 'Variable:0' shape=() dtype=int32> tp\n",
      "tracking <tf.Variable 'Variable_1:0' shape=() dtype=int32> fp\n",
      "tracking <tf.Variable 'Variable_2:0' shape=() dtype=int32> tp\n",
      "tracking <tf.Variable 'Variable_3:0' shape=() dtype=int32> fn\n",
      "tracking <tf.Variable 'Variable_4:0' shape=() dtype=int32> tp\n",
      "tracking <tf.Variable 'Variable_5:0' shape=() dtype=int32> fp\n",
      "tracking <tf.Variable 'Variable_6:0' shape=() dtype=int32> tp\n",
      "tracking <tf.Variable 'Variable_7:0' shape=() dtype=int32> fn\n"
     ]
    }
   ],
   "source": [
    "#AlexNet Architecture for EC estimation\n",
    "model2 = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(250,250,1)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1048, activation='relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "model2.summary()\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy',keras_metrics.precision(),keras_metrics.recall(),keras_metrics.f1_score()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "veterinary-november",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Unrecognized keyword arguments:', dict_keys(['ragged']))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-070fbbfad3ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'faceRecognitionModel.h5'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'binary_precision'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mkeras_metrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_precision\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'binary_recall'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mkeras_metrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_recall\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'binary_f1_score'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mkeras_metrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_f1_score\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    144\u001b[0m       h5py is not None and (\n\u001b[0;32m    145\u001b[0m           isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[1;32m--> 146\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model_from_hdf5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     model = model_config_lib.model_from_config(model_config,\n\u001b[1;32m--> 212\u001b[1;33m                                                custom_objects=custom_objects)\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;31m# set weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\model_config.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m     53\u001b[0m                     '`Sequential.from_config(config)`?')\n\u001b[0;32m     54\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m  \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m     87\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m       printable_module_name='layer')\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    190\u001b[0m             custom_objects=dict(\n\u001b[0;32m    191\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_GLOBAL_CUSTOM_OBJECTS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m                 list(custom_objects.items())))\n\u001b[0m\u001b[0;32m    193\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mfrom_config\u001b[1;34m(cls, config, custom_objects)\u001b[0m\n\u001b[0;32m    350\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer_config\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayer_configs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m       layer = layer_module.deserialize(layer_config,\n\u001b[1;32m--> 352\u001b[1;33m                                        custom_objects=custom_objects)\n\u001b[0m\u001b[0;32m    353\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbuild_input_shape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m     87\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m       printable_module_name='layer')\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    192\u001b[0m                 list(custom_objects.items())))\n\u001b[0;32m    193\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m       \u001b[1;31m# Then `cls` may be a function returning a class.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mfrom_config\u001b[1;34m(cls, config)\u001b[0m\n\u001b[0;32m    444\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \"\"\"\n\u001b[1;32m--> 446\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\New_Environment_For_Keras\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_shape, batch_size, dtype, input_tensor, sparse, name, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_input_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized keyword arguments:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: ('Unrecognized keyword arguments:', dict_keys(['ragged']))"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('faceRecognitionModel.h5',custom_objects={'binary_precision':keras_metrics.binary_precision,'binary_recall':keras_metrics.binary_recall,'binary_f1_score':keras_metrics.binary_f1_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "moral-forward",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded!\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "savedModel = model2.load_weights('faceRecognitionModel')\n",
    "print('Model Loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "lyric-subdivision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "liked-nothing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mahmood Yousaf\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\base_layer.py:1348: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`layer.updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "13/13 [==============================] - 1s 24ms/step - loss: 0.0443 - accuracy: 0.9975 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.044279154390096664, 0.9975000023841858, 1.0, 1.0, 0.9999999403953552]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_test,Y_test,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-charles",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_model():\n",
    "    FaceClassifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    def face_detection(image):\n",
    "        gray_scale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        detected_face = FaceClassifier.detectMultiScale(gray_scale, 1.3, 5)\n",
    "        \n",
    "        if detected_face is ():\n",
    "            return None\n",
    "        for (x,y,w,h) in detected_face:\n",
    "            face = image[y:y+h,x:x+w]\n",
    "        return face\n",
    "    \n",
    "    videoCapture = cv2.VideoCapture(0)    \n",
    "    while True:\n",
    "        ret, frame = videoCapture.read()\n",
    "        if face_detection(frame) is not None:\n",
    "            face = cv2.resize(face_detection(frame), (250,250))\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "            cv2.putText(face, str(\"User\"), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2 )\n",
    "            cv2.imshow(\"Cropped_Face\", face)\n",
    "            prediction = model2.predict_classes(face.reshape(-1, 250, 250, 1))\n",
    "            print(prediction)\n",
    "            if cv2.waitKey(1)==13:\n",
    "                break\n",
    "                \n",
    "    videoCapture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Data Collection is completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-joint",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model2.predict_pr(X[19].reshape(-1, 250, 250, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-specification",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-reproduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-occasions",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
